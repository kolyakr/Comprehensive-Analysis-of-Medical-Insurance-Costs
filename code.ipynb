{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70ea2eae",
   "metadata": {},
   "source": [
    "This project explores the Medical Cost Personal Dataset through the lenses of both Regression and Classification. The goal is to build a robust system that can not only predict the specific dollar amount of medical insurance charges but also categorize individuals into \"cost brackets\" with high confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea09d39",
   "metadata": {},
   "source": [
    "### Table of contents\n",
    "\n",
    "| Section | Phase | Technical Highlights |\n",
    "| :--- | :--- | :--- |\n",
    "| **I** | [**Data Preparation**](#prep) | Train/Test Split (80/20), Standardizing, & One-Hot Encoding. |\n",
    "| **II** | [**Probabilistic Regression**](#regression) | Ridge/Lasso & **95% Confidence Intervals** implementation. |\n",
    "| **III** | [**Ensemble Methods**](#ensemble) | **Bagging, Boosting (XGBoost)**, and **Stacking** architectures. |\n",
    "| **IV** | [**Discretization Strategy**](#discrete) | Converting `charges` via **Equal-Width Binning** into classes. |\n",
    "| **V** | [**Probability & Overfitting**](#probs) | Analyzing **Softmax distributions** and Underfitting vs. Overfitting. |\n",
    "| **VI** | [**GridSearchCV Optimization**](#opt) | Hyperparameter tuning for the best classification variant. |\n",
    "| **VII** | [**Metric Bridging**](#metrics) | Converting **MAE to Accuracy** via mathematical transformations. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff87076e",
   "metadata": {},
   "source": [
    "<a id=\"prep\"></a>\n",
    "#### Phase I: Data Preparation & Preprocessing\n",
    "> **Goal:** Create a clean, standardized pipeline. We ensure that parameters (mean, std) from the training set are strictly applied to the test set to avoid data leakage.\n",
    "\n",
    "* **Numeric:** Age, BMI, Children (Standardization).\n",
    "* **Categorical:** Sex, Smoker, Region (One-Hot Encoding).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb521e3",
   "metadata": {},
   "source": [
    "<a id=\"regression\"></a>\n",
    "#### Phase II: Probabilistic Regression\n",
    "> **Goal:** Predict continuous costs with statistical uncertainty.\n",
    "\n",
    "We implement baseline models and calculate **95% Confidence Intervals**. For a given prediction $\\hat{y}$, the interval is defined as:\n",
    "$$\\hat{y} \\pm t_{\\alpha/2, n-2} \\cdot \\sigma$$\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99457dca",
   "metadata": {},
   "source": [
    "<a id=\"ensemble\"></a>\n",
    "#### Phase III: Ensemble Methods\n",
    "> **Goal:** Leverage multi-model architectures to minimize variance (Bagging) and bias (Boosting).\n",
    "\n",
    "* **Bagging:** Random Forest Regressor.\n",
    "* **Boosting:** XGBoost / Gradient Boosting.\n",
    "* **Stacking:** A meta-model trained on the predictions of base learners.\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabdc090",
   "metadata": {},
   "source": [
    "<a id=\"discrete\"></a>\n",
    "#### Phase IV: Discretization (Regression to Classification)\n",
    "> **Goal:** Transform the problem into a classification task using **Equal-Width Binning**.\n",
    "\n",
    "We divide the `charges` range into $N$ equal intervals to categorize individuals into risk levels (e.g., Low, Medium, High).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1c1c59",
   "metadata": {},
   "source": [
    "<a id=\"probs\"></a>\n",
    "#### Phase V: Probability Distributions & Confidence\n",
    "> **Goal:** Evaluate model \"certainty\" and diagnose the fit.\n",
    "\n",
    "We analyze the **Softmax** output (or `predict_proba`) to visualize how \"sure\" the model is.\n",
    "* **Overfitting:** High confidence on incorrect predictions.\n",
    "* **Underfitting:** Uniformly low confidence across all classes.\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84046bfb",
   "metadata": {},
   "source": [
    "<a id=\"opt\"></a>\n",
    "#### Phase VI: Optimization via GridSearchCV\n",
    "> **Goal:** Fine-tune the best-performing classifier.\n",
    "\n",
    "Using a parameter grid, we find the optimal `max_depth`, `learning_rate`, and `n_estimators` to maximize our F1-score.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa876002",
   "metadata": {},
   "source": [
    "<a id=\"metrics\"></a>\n",
    "#### Phase VII: Metric Bridging & Final Conversion\n",
    "> **Goal:** Mathematically link Error (Regression) to Accuracy (Classification).\n",
    "\n",
    "We investigate if a model with a lower **MAE** (Mean Absolute Error) naturally results in higher **Accuracy** when the results are discretized.\n",
    "$$\\text{Accuracy} \\approx f(\\text{MAE}, \\text{Bin Width})$$\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
